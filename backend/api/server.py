from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import pandas as pd
import os

from scheduler import start_scheduler   # ðŸ”¥ scheduler runs scraper every 20 mins

# Base directory: backend/api
BASE_DIR = os.path.dirname(__file__)

# CSV generated by scraper
CSV_PATH = os.path.join(BASE_DIR, "../scraper/sydney_events.csv")


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Runs once when the FastAPI app starts.
    Starts the background scheduler.
    """
    start_scheduler()
    print("[API] Scheduler started")
    yield
    print("[API] Shutting down")


app = FastAPI(lifespan=lifespan)

# CORS (Netlify + Render compatible)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],   # OK for assignment/demo
    allow_methods=["*"],
    allow_headers=["*"]
)


@app.get("/events")
def get_events():
    """
    Returns latest events from CSV.
    Dates are returned as-is (strings).
    """
    if not os.path.exists(CSV_PATH):
        return []

    df = pd.read_csv(CSV_PATH)

    # ðŸ”¥ DO NOT parse dates â€” keep strings
    if "created_at" in df.columns:
        df = df.sort_values("created_at", ascending=False)

    return df.fillna("").to_dict(orient="records")
